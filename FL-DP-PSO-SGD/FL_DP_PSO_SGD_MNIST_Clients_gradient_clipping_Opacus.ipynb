{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julialunna/Artificial-Intelligence/blob/main/FL-DP-PSO-SGD/FL_DP_PSO_SGD_MNIST_Clients_gradient_clipping_Opacus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pega o erro de cada um e compara. A part√≠cula com menor erro pede o gbest."
      ],
      "metadata": {
        "id": "_CPCXVr31FDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opacus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-88k_b5RxwsM",
        "outputId": "9951d9d5-739d-461d-974e-f6338379a64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opacus in /usr/local/lib/python3.11/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, Subset, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import random\n",
        "import csv\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
        "from opacus.accountants.utils import get_noise_multiplier\n",
        "from copy import deepcopy"
      ],
      "metadata": {
        "id": "AasvJNQd54yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, device, input_size=28*28, hidden_size=256, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.device = device\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, 128)\n",
        "        self.fc4 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()  # ReLU √© reutilizado\n",
        "        self.to(device)  # Move o modelo para o dispositivo especificado\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Achata o tensor de entrada\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc4(x)  # Chamada correta da camada fc4\n",
        "        return x"
      ],
      "metadata": {
        "id": "DK3gmoasMO_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defini√ß√µes dos hiperpar√¢metros\n",
        "NUM_CLIENTES = 5\n",
        "NUM_PARTICULAS = 25\n",
        "NUM_RODADAS = 10\n",
        "INERCIA, C1, C2 = 0.9, 0.8, 0.9\n",
        "MAX_NORM = 2.0\n",
        "SUBSET_SIZE = 12000\n",
        "BATCH_SIZE = 400\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'training on {DEVICE}')\n",
        "\n",
        "# Criando o modelo global\n",
        "modelo_global = MLP(DEVICE, hidden_size=256)\n",
        "criterio = nn.CrossEntropyLoss()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOsKzlgWLN5r",
        "outputId": "7e20a956-0e14-4a24-c811-4adc926883e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seeds para reprodutibilidade\n",
        "random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "\n",
        "\n",
        "# Fun√ß√£o para criar um subconjunto aleat√≥rio de um dataset\n",
        "def create_subset(dataset, num_clients):\n",
        "    indices = list(range(len(dataset)))  # Lista de todos os √≠ndices\n",
        "    random.shuffle(indices)  # Embaralha os √≠ndices para aleatoriedade\n",
        "\n",
        "    subset_size = len(indices) // num_clients  # Tamanho de cada subconjunto\n",
        "    subsets = [Subset(dataset, indices[i * subset_size : (i + 1) * subset_size]) for i in range(num_clients)]\n",
        "\n",
        "    dataloaders = [\n",
        "        DataLoader(subset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "        for subset in subsets\n",
        "    ]\n",
        "    return dataloaders\n",
        "\n",
        "    return dataloaders\n",
        "def add_module_prefix(state_dict):\n",
        "    new_state_dict = {}\n",
        "    for key, value in state_dict.items():\n",
        "        new_key = f\"_module.{key}\"  # Adiciona o prefixo `_module`\n",
        "        new_state_dict[new_key] = value\n",
        "    return new_state_dict\n",
        "\n",
        "class Particula:\n",
        "    def __init__(self, particle_id, modelo_cliente):\n",
        "        self.particle_id = particle_id\n",
        "        self.pesos = {f\"_module.{key}\": value.clone() for key, value in modelo_cliente.state_dict().items()}\n",
        "        self.melhor_pesos = copy.deepcopy(self.pesos)  # pbest (melhor posi√ß√£o da part√≠cula)\n",
        "        self.melhor_erro = float('inf')  # Melhor erro alcan√ßado\n",
        "        self.velocidade = {name: torch.zeros_like(param) for name, param in self.pesos.items()}  # Velocidade do PSO\n",
        "        self.device = modelo_cliente.device  # Dispositivo do modelo\n",
        "\n",
        "    def atualizar_pso(self, global_best_pesos, INERCIA, C1, C2, rodada):\n",
        "        \"\"\"Atualiza os pesos da part√≠cula usando a equa√ß√£o do PSO.\"\"\"\n",
        "        global_best_pesos_ajustados = global_best_pesos\n",
        "        if(rodada == 0):\n",
        "          global_best_pesos_ajustados = {f\"_module.{key}\": value for key, value in global_best_pesos.items()}\n",
        "        for name in self.pesos:\n",
        "            local_rand = random.random()\n",
        "            global_rand = random.random()\n",
        "            self.velocidade[name] = (\n",
        "                INERCIA * self.velocidade[name] +\n",
        "                C1 * local_rand * (self.melhor_pesos[name] - self.pesos[name]) +\n",
        "                C2 * global_rand * (global_best_pesos_ajustados[name] - self.pesos[name])\n",
        "            )\n",
        "            self.pesos[name] += self.velocidade[name]\n",
        "            ''' sigma = SENSITIVITY * torch.sqrt((2.0 * torch.log(torch.tensor(1.0 / DELTA))).clone().detach()) / EPSILON\n",
        "\n",
        "              # Gerar ru√≠do diretamente com a distribui√ß√£o normal do PyTorch (muito mais eficiente!)\n",
        "              noise = torch.normal(mean=0, std=sigma, size=self.velocidade[name].shape, device=self.device)\n",
        "              self.velocidade[name] += noise\n",
        "              #clipping velocity\n",
        "              self.velocidade[name] = torch.clamp(self.velocidade[name], -MAX_VELOCITY, MAX_VELOCITY)'''\n",
        "\n",
        "    def avaliar_perda(self, modelo_cliente, criterio, dados):\n",
        "        \"\"\"Calcula a perda da part√≠cula no modelo do cliente.\"\"\"\n",
        "        #pesos_ajustados = {f\"_module.{key}\": value for key, value in self.pesos.items()}\n",
        "\n",
        "        modelo_cliente.load_state_dict(self.pesos)  # Aplica os pesos da part√≠cula no modelo do cliente\n",
        "        modelo_cliente.eval()\n",
        "        total_loss = 0\n",
        "        device = next(modelo_cliente.parameters()).device\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dados:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = modelo_cliente(inputs)\n",
        "                loss = criterio(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        return total_loss / len(dados)\n",
        "\n",
        "\n",
        "class Cliente:\n",
        "    def __init__(self, cliente_id, modelo_global, dados, num_particulas=5):\n",
        "        self.cliente_id = cliente_id\n",
        "        self.modelo = copy.deepcopy(modelo_global)  # Cada cliente tem seu pr√≥prio modelo\n",
        "        self.dados = dados\n",
        "        self.num_particulas = num_particulas\n",
        "        self.particulas = []\n",
        "        self.melhor_particula = None\n",
        "        self.inicializar_particulas(num_particulas)\n",
        "        self.otimizador = optim.Adam(self.modelo.parameters(), lr=0.009, weight_decay=1e-5)\n",
        "\n",
        "    def inicializar_particulas(self, num_particulas):\n",
        "        \"\"\"Cria um conjunto de part√≠culas associadas ao cliente.\"\"\"\n",
        "        self.particulas = [Particula(i, self.modelo) for i in range(num_particulas)]\n",
        "\n",
        "    def treinar_com_pso(self, INERCIA, C1, C2, global_best_pesos, criterio, rodada):\n",
        "        \"\"\"Treina as part√≠culas usando PSO e atualiza a melhor part√≠cula local.\"\"\"\n",
        "\n",
        "        for particula in self.particulas:\n",
        "            particula.atualizar_pso(global_best_pesos, INERCIA, C1, C2, rodada)\n",
        "            erro = particula.avaliar_perda(self.modelo, criterio, self.dados)\n",
        "            if erro < particula.melhor_erro:\n",
        "                particula.melhor_erro = erro\n",
        "                particula.melhor_pesos = copy.deepcopy(particula.pesos)\n",
        "\n",
        "        self.selecionar_melhor_particula()\n",
        "\n",
        "    def refinar_com_adam(self, criterio):\n",
        "        \"\"\"Refina os pesos da melhor part√≠cula usando Adam.\"\"\"\n",
        "        self.modelo.load_state_dict(self.melhor_particula.melhor_pesos)\n",
        "        #train_loader = DataLoader(self.dados, batch_size=32, shuffle=True)\n",
        "        device = next(self.modelo.parameters()).device\n",
        "        self.modelo.train()\n",
        "        for i in range(1):  # 10 √©pocas de refinamento com Adam\n",
        "          with BatchMemoryManager(data_loader=self.dados, max_physical_batch_size=BATCH_SIZE, optimizer=self.otimizador) as new_data_loader:\n",
        "            for inputs, labels in new_data_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                self.otimizador.zero_grad()\n",
        "                outputs = self.modelo(inputs)\n",
        "                loss = criterio(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.otimizador.step()\n",
        "        # Atualiza os pesos da melhor part√≠cula com os pesos refinados pelo Adam\n",
        "        self.melhor_particula.pesos = copy.deepcopy(self.modelo.state_dict())\n",
        "\n",
        "    def selecionar_melhor_particula(self):\n",
        "        \"\"\"Seleciona a melhor part√≠cula do cliente.\"\"\"\n",
        "        self.melhor_particula = min(self.particulas, key=lambda p: p.melhor_erro)\n",
        "\n",
        "\n",
        "def treinar_federado(modelo_global, clientes, criterio, num_rodadas, INERCIA, C1, C2, testloader):\n",
        "    \"\"\"Treina os clientes localmente e sincroniza com o servidor central, validando a acur√°cia.\"\"\"\n",
        "\n",
        "    melhor_peso_global = copy.deepcopy(modelo_global.state_dict())  # Inicializa com o modelo global\n",
        "    melhor_erro_global = float('inf')\n",
        "    for rodada in range(num_rodadas):\n",
        "        resultados_rodada = []\n",
        "\n",
        "\n",
        "        for cliente in clientes:\n",
        "            cliente.treinar_com_pso(INERCIA, C1, C2, melhor_peso_global, criterio, rodada)  # Treino com PSO\n",
        "            cliente.refinar_com_adam(criterio)  # Refinamento com Adam\n",
        "            erro_cliente = cliente.melhor_particula.melhor_erro  # Obt√©m o melhor erro do cliente\n",
        "            resultados_rodada.append((cliente.cliente_id, erro_cliente))\n",
        "\n",
        "        resultados_sorted = sorted(resultados_rodada, key=lambda x: x[1])\n",
        "        top_3_results = resultados_sorted[:3]\n",
        "\n",
        "        melhor_cliente = random.choice(top_3_results)\n",
        "        melhor_cliente_id = melhor_cliente[0]\n",
        "        melhor_erro_cliente = melhor_cliente[1]\n",
        "\n",
        "        melhor_peso_global = copy.deepcopy(clientes[melhor_cliente_id].melhor_particula.pesos)\n",
        "        melhor_peso_global_ajustado = {key.replace(\"_module.\", \"\"): value for key, value in melhor_peso_global.items()}\n",
        "        melhor_erro_global = melhor_erro_cliente\n",
        "\n",
        "        modelo_global.load_state_dict(melhor_peso_global_ajustado)\n",
        "\n",
        "        test_loss, test_accuracy = avaliar_modelo(modelo_global, criterio, testloader)\n",
        "\n",
        "\n",
        "        print(f\"Rodada {rodada+1}/{num_rodadas}: Cliente {melhor_cliente_id} enviou os pesos.\")\n",
        "        print(f\"Erro Global Atualizado: {melhor_erro_global:.4f}\")\n",
        "        print(f\"Teste -> Perda: {test_loss:.4f}, Acur√°cia: {test_accuracy:.2f}%\\n\")\n",
        "\n",
        "    print(\"Treinamento Federado Finalizado!\")\n",
        "\n",
        "def avaliar_modelo(modelo, criterio, testloader):\n",
        "    \"\"\"Avalia o modelo global no conjunto de teste.\"\"\"\n",
        "    modelo.eval()  # Modo de avalia√ß√£o\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = modelo(inputs)\n",
        "            loss = criterio(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    test_loss = total_loss / len(testloader)\n",
        "    test_accuracy = (correct / total_samples) * 100\n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "X_train = mnist_train.data.view(-1, 28*28).numpy()  # Flatten (Transforma 28x28 em 784)\n",
        "y_train = mnist_train.targets.numpy()  # Labels\n",
        "\n",
        "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
        "X_test = mnist_test.data.view(-1, 28*28).numpy()  # Flatten (Transforma 28x28 em 784)\n",
        "y_test = mnist_test.targets.numpy()  # Labels\n",
        "\n",
        "# Dividir treino e teste manualmente como no Iris\n",
        "\n",
        "# Normalizar como no Iris\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Converter para tensores\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Criar datasets como no Iris\n",
        "trainset = TensorDataset(X_train, y_train)\n",
        "testset = TensorDataset(X_test, y_test)\n",
        "\n",
        "\n",
        "trainloaders = create_subset(trainset, NUM_CLIENTES)\n",
        "\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "noise = get_noise_multiplier(target_epsilon = 5,\n",
        "                             target_delta = 1e-5,\n",
        "                             sample_rate = BATCH_SIZE/12000,\n",
        "                             epochs = 10)\n",
        "\n",
        "\n",
        "# Criando os clientes\n",
        "clientes = [Cliente(i, modelo_global, trainloaders[i], NUM_PARTICULAS) for i in range(NUM_CLIENTES)]\n",
        "privacy_engine_client_0 = PrivacyEngine()\n",
        "privacy_engine_client_1 = PrivacyEngine()\n",
        "privacy_engine_client_2 = PrivacyEngine()\n",
        "privacy_engine_client_3 = PrivacyEngine()\n",
        "privacy_engine_client_4 = PrivacyEngine()\n",
        "\n",
        "\n",
        "\n",
        "clientes[0].modelo, clientes[0].otimizador, clientes[0].dados = privacy_engine_client_0.make_private(\n",
        "    module=clientes[0].modelo,\n",
        "    optimizer=clientes[0].otimizador,\n",
        "    data_loader=clientes[0].dados,  # Seu DataLoader\n",
        "    noise_multiplier=noise,      # Controle o n√≠vel de ru√≠do\n",
        "    max_grad_norm=1.0,         # Clipping dos gradientes\n",
        ")\n",
        "clientes[1].modelo, clientes[1].otimizador, clientes[1].dados = privacy_engine_client_1.make_private(\n",
        "    module=clientes[1].modelo,\n",
        "    optimizer=clientes[1].otimizador,\n",
        "    data_loader=clientes[1].dados,  # Seu DataLoader\n",
        "    noise_multiplier=noise,      # Controle o n√≠vel de ru√≠do\n",
        "    max_grad_norm=1.0,         # Clipping dos gradientes\n",
        ")\n",
        "clientes[2].modelo, clientes[2].otimizador, clientes[2].dados = privacy_engine_client_2.make_private(\n",
        "    module=clientes[2].modelo,\n",
        "    optimizer=clientes[2].otimizador,\n",
        "    data_loader=clientes[2].dados,  # Seu DataLoader\n",
        "    noise_multiplier=noise,      # Controle o n√≠vel de ru√≠do\n",
        "    max_grad_norm=1.0,         # Clipping dos gradientes\n",
        ")\n",
        "clientes[3].modelo, clientes[3].otimizador, clientes[3].dados = privacy_engine_client_3.make_private(\n",
        "    module=clientes[3].modelo,\n",
        "    optimizer=clientes[3].otimizador,\n",
        "    data_loader=clientes[3].dados,  # Seu DataLoader\n",
        "    noise_multiplier=noise,      # Controle o n√≠vel de ru√≠do\n",
        "    max_grad_norm=1.0,         # Clipping dos gradientes\n",
        ")\n",
        "clientes[4].modelo, clientes[4].otimizador, clientes[4].dados = privacy_engine_client_4.make_private(\n",
        "    module=clientes[4].modelo,\n",
        "    optimizer=clientes[4].otimizador,\n",
        "    data_loader=clientes[4].dados,  # Seu DataLoader\n",
        "    noise_multiplier=noise,      # Controle o n√≠vel de ru√≠do\n",
        "    max_grad_norm=1.0,         # Clipping dos gradientes\n",
        ")\n",
        "\n",
        "# Executando o treinamento federado\n",
        "treinar_federado(modelo_global, clientes, criterio, NUM_RODADAS, INERCIA, C1, C2, testloader)\n",
        "print(f\"Or√ßamento de privacidade (epsilon) Cliente 0: {privacy_engine_client_0.get_epsilon(delta = 1e-5)}\")\n",
        "print(f\"Or√ßamento de privacidade (epsilon) Cliente 1: {privacy_engine_client_1.get_epsilon(delta = 1e-5)}\")\n",
        "print(f\"Or√ßamento de privacidade (epsilon) Cliente 2: {privacy_engine_client_2.get_epsilon(delta = 1e-5)}\")\n",
        "print(f\"Or√ßamento de privacidade (epsilon) Cliente 3: {privacy_engine_client_3.get_epsilon(delta = 1e-5)}\")\n",
        "print(f\"Or√ßamento de privacidade (epsilon) Cliente 4: {privacy_engine_client_4.get_epsilon(delta = 1e-5)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkL-eId7AF03",
        "outputId": "2c76fcb2-8ae8-49a1-f511-4d48a2a3b36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodada 1/10: Cliente 0 enviou os pesos.\n",
            "Erro Global Atualizado: 2.2985\n",
            "Teste -> Perda: 0.8366, Acur√°cia: 84.50%\n",
            "\n",
            "Rodada 2/10: Cliente 0 enviou os pesos.\n",
            "Erro Global Atualizado: 0.5436\n",
            "Teste -> Perda: 0.6486, Acur√°cia: 88.26%\n",
            "\n",
            "Rodada 3/10: Cliente 1 enviou os pesos.\n",
            "Erro Global Atualizado: 0.4427\n",
            "Teste -> Perda: 0.6451, Acur√°cia: 88.81%\n",
            "\n",
            "Rodada 4/10: Cliente 1 enviou os pesos.\n",
            "Erro Global Atualizado: 0.4427\n",
            "Teste -> Perda: 0.5999, Acur√°cia: 89.21%\n",
            "\n",
            "Rodada 5/10: Cliente 1 enviou os pesos.\n",
            "Erro Global Atualizado: 0.3906\n",
            "Teste -> Perda: 0.6592, Acur√°cia: 89.27%\n",
            "\n",
            "Rodada 6/10: Cliente 0 enviou os pesos.\n",
            "Erro Global Atualizado: 0.4332\n",
            "Teste -> Perda: 0.6088, Acur√°cia: 89.17%\n",
            "\n",
            "Rodada 7/10: Cliente 0 enviou os pesos.\n",
            "Erro Global Atualizado: 0.3734\n",
            "Teste -> Perda: 0.5920, Acur√°cia: 89.57%\n",
            "\n",
            "Rodada 8/10: Cliente 2 enviou os pesos.\n",
            "Erro Global Atualizado: 0.3951\n",
            "Teste -> Perda: 0.6076, Acur√°cia: 89.70%\n",
            "\n",
            "Rodada 9/10: Cliente 0 enviou os pesos.\n",
            "Erro Global Atualizado: 0.3734\n",
            "Teste -> Perda: 0.5579, Acur√°cia: 89.70%\n",
            "\n",
            "Rodada 10/10: Cliente 2 enviou os pesos.\n",
            "Erro Global Atualizado: 0.3883\n",
            "Teste -> Perda: 0.5737, Acur√°cia: 89.96%\n",
            "\n",
            "Treinamento Federado Finalizado!\n",
            "Or√ßamento de privacidade (epsilon) Cliente 0: 4.417680295219723\n",
            "Or√ßamento de privacidade (epsilon) Cliente 1: 4.417680295219723\n",
            "Or√ßamento de privacidade (epsilon) Cliente 2: 4.417680295219723\n",
            "Or√ßamento de privacidade (epsilon) Cliente 3: 4.417680295219723\n",
            "Or√ßamento de privacidade (epsilon) Cliente 4: 4.417680295219723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " '''sigma = SENSITIVITY * torch.sqrt((2.0 * torch.log(torch.tensor(1.0 / DELTA))).clone().detach()) / EPSILON\n",
        "              if i==4:\n",
        "                # Percorrer todos os par√¢metros do modelo e adicionar ru√≠do aos gradientes\n",
        "                for param in self.modelo.parameters():\n",
        "                    if param.grad is not None:\n",
        "                        torch.nn.utils.clip_grad_norm_(self.modelo.parameters(), MAX_NORM)\n",
        "                        noise = torch.normal(mean=0, std=sigma, size=param.grad.shape, device=param.grad.device)\n",
        "                        param.grad += noise  # üîπ Adiciona ru√≠do diretamente ao gradiente'''"
      ],
      "metadata": {
        "id": "w7tgCKOD85iX"
      }
    }
  ]
}