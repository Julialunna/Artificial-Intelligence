{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julialunna/Artificial-Intelligence/blob/main/FL-DP-PSO-SGD/FL_DP_PSO_SGD_MNIST_Clients_gradient_clipping_Opacus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pega o erro de cada um e compara. A partícula com menor erro pede o gbest."
      ],
      "metadata": {
        "id": "_CPCXVr31FDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opacus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-88k_b5RxwsM",
        "outputId": "9951d9d5-739d-461d-974e-f6338379a64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opacus in /usr/local/lib/python3.11/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, Subset, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import random\n",
        "import csv\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
        "from opacus.accountants.utils import get_noise_multiplier\n",
        "from copy import deepcopy"
      ],
      "metadata": {
        "id": "AasvJNQd54yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, device, input_size=28*28, hidden_size=256, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.device = device\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, 128)\n",
        "        self.fc4 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()  # ReLU é reutilizado\n",
        "        self.to(device)  # Move o modelo para o dispositivo especificado\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Achata o tensor de entrada\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc4(x)  # Chamada correta da camada fc4\n",
        "        return x"
      ],
      "metadata": {
        "id": "DK3gmoasMO_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definições dos hiperparâmetros\n",
        "NUM_CLIENTES = 5\n",
        "NUM_PARTICULAS = 25\n",
        "NUM_RODADAS = 10\n",
        "INERCIA, C1, C2 = 0.9, 0.8, 0.9\n",
        "MAX_NORM = 2.0\n",
        "SUBSET_SIZE = 12000\n",
        "BATCH_SIZE = 400\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'training on {DEVICE}')\n",
        "\n",
        "# Criando o modelo global\n",
        "modelo_global = MLP(DEVICE, hidden_size=256)\n",
        "criterio = nn.CrossEntropyLoss()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOsKzlgWLN5r",
        "outputId": "7e20a956-0e14-4a24-c811-4adc926883e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seeds para reprodutibilidade\n",
        "random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "\n",
        "\n",
        "# Função para criar um subconjunto aleatório de um dataset\n",
        "def create_subset(dataset, num_clients):\n",
        "    indices = list(range(len(dataset)))  # Lista de todos os índices\n",
        "    random.shuffle(indices)  # Embaralha os índices para aleatoriedade\n",
        "\n",
        "    subset_size = len(indices) // num_clients  # Tamanho de cada subconjunto\n",
        "    subsets = [Subset(dataset, indices[i * subset_size : (i + 1) * subset_size]) for i in range(num_clients)]\n",
        "\n",
        "    dataloaders = [\n",
        "        DataLoader(subset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "        for subset in subsets\n",
        "    ]\n",
        "    return dataloaders\n",
        "\n",
        "    return dataloaders\n",
        "def add_module_prefix(state_dict):\n",
        "    new_state_dict = {}\n",
        "    for key, value in state_dict.items():\n",
        "        new_key = f\"_module.{key}\"  # Adiciona o prefixo `_module`\n",
        "        new_state_dict[new_key] = value\n",
        "    return new_state_dict\n",
        "\n",
        "class Particula:\n",
        "    def __init__(self, particle_id, modelo_cliente):\n",
        "        self.particle_id = particle_id\n",
        "        self.pesos = {f\"_module.{key}\": value.clone() for key, value in modelo_cliente.state_dict().items()}\n",
        "        self.melhor_pesos = copy.deepcopy(self.pesos)  # pbest (melhor posição da partícula)\n",
        "        self.melhor_erro = float('inf')  # Melhor erro alcançado\n",
        "        self.velocidade = {name: torch.zeros_like(param) for name, param in self.pesos.items()}  # Velocidade do PSO\n",
        "        self.device = modelo_cliente.device  # Dispositivo do modelo\n",
        "\n",
        "    def atualizar_pso(self, global_best_pesos, INERCIA, C1, C2, rodada):\n",
        "        \"\"\"Atualiza os pesos da partícula usando a equação do PSO.\"\"\"\n",
        "        global_best_pesos_ajustados = global_best_pesos\n",
        "        if(rodada == 0):\n",
        "          global_best_pesos_ajustados = {f\"_module.{key}\": value for key, value in global_best_pesos.items()}\n",
        "        for name in self.pesos:\n",
        "            local_rand = random.random()\n",
        "            global_rand = random.random()\n",
        "            self.velocidade[name] = (\n",
        "                INERCIA * self.velocidade[name] +\n",
        "                C1 * local_rand * (self.melhor_pesos[name] - self.pesos[name]) +\n",
        "                C2 * global_rand * (global_best_pesos_ajustados[name] - self.pesos[name])\n",
        "            )\n",
        "            self.pesos[name] += self.velocidade[name]\n",
        "            ''' sigma = SENSITIVITY * torch.sqrt((2.0 * torch.log(torch.tensor(1.0 / DELTA))).clone().detach()) / EPSILON\n",
        "\n",
        "              # Gerar ruído diretamente com a distribuição normal do PyTorch (muito mais eficiente!)\n",
        "              noise = torch.normal(mean=0, std=sigma, size=self.velocidade[name].shape, device=self.device)\n",
        "              self.velocidade[name] += noise\n",
        "              #clipping velocity\n",
        "              self.velocidade[name] = torch.clamp(self.velocidade[name], -MAX_VELOCITY, MAX_VELOCITY)'''\n",
        "\n",
        "    def avaliar_perda(self, modelo_cliente, criterio, dados):\n",
        "        \"\"\"Calcula a perda da partícula no modelo do cliente.\"\"\"\n",
        "        #pesos_ajustados = {f\"_module.{key}\": value for key, value in self.pesos.items()}\n",
        "\n",
        "        modelo_cliente.load_state_dict(self.pesos)  # Aplica os pesos da partícula no modelo do cliente\n",
        "        modelo_cliente.eval()\n",
        "        total_loss = 0\n",
        "        device = next(modelo_cliente.parameters()).device\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dados:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = modelo_cliente(inputs)\n",
        "                loss = criterio(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        return total_loss / len(dados)\n",
        "\n",
        "\n",
        "class Cliente:\n",
        "    def __init__(self, cliente_id, modelo_global, dados, num_particulas=5):\n",
        "        self.cliente_id = cliente_id\n",
        "        self.modelo = copy.deepcopy(modelo_global)  # Cada cliente tem seu próprio modelo\n",
        "        self.dados = dados\n",
        "        self.num_particulas = num_particulas\n",
        "        self.particulas = []\n",
        "        self.melhor_particula = None\n",
        "        self.inicializar_particulas(num_particulas)\n",
        "        self.otimizador = optim.Adam(self.modelo.parameters(), lr=0.009, weight_decay=1e-5)\n",
        "\n",
        "    def inicializar_particulas(self, num_particulas):\n",
        "        \"\"\"Cria um conjunto de partículas associadas ao cliente.\"\"\"\n",
        "        self.particulas = [Particula(i, self.modelo) for i in range(num_particulas)]\n",
        "\n",
        "    def treinar_com_pso(self, INERCIA, C1, C2, global_best_pesos, criterio, rodada):\n",
        "        \"\"\"Treina as partículas usando PSO e atualiza a melhor partícula local.\"\"\"\n",
        "\n",
        "        for particula in self.particulas:\n",
        "            particula.atualizar_pso(global_best_pesos, INERCIA, C1, C2, rodada)\n",
        "            erro = particula.avaliar_perda(self.modelo, criterio, self.dados)\n",
        "            if erro < particula.melhor_erro:\n",
        "                particula.melhor_erro = erro\n",
        "                particula.melhor_pesos = copy.deepcopy(particula.pesos)\n",
        "\n",
        "        self.selecionar_melhor_particula()\n",
        "\n",
        "    def refinar_com_adam(self, criterio):\n",
        "        \"\"\"Refina os pesos da melhor partícula usando Adam.\"\"\"\n",
        "        self.modelo.load_state_dict(self.melhor_particula.melhor_pesos)\n",
        "        #train_loader = DataLoader(self.dados, batch_size=32, shuffle=True)\n",
        "        device = next(self.modelo.parameters()).device\n",
        "        self.modelo.train()\n",
        "        for i in range(1):  # 10 épocas de refinamento com Adam\n",
        "          with BatchMemoryManager(data_loader=self.dados, max_physical_batch_size=BATCH_SIZE, optimizer=self.otimizador) as new_data_loader:\n",
        "            for inputs, labels in new_data_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                self.otimizador.zero_grad()\n",
        "                outputs = self.modelo(inputs)\n",
        "                loss = criterio(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.otimizador.step()\n",
        "        # Atualiza os pesos da melhor partícula com os pesos refinados pelo Adam\n",
        "        self.melhor_particula.pesos = copy.deepcopy(self.modelo.state_dict())\n",
        "\n",
        "    def selecionar_melhor_particula(self):\n",
        "        \"\"\"Seleciona a melhor partícula do cliente.\"\"\"\n",
        "        self.melhor_particula = min(self.particulas, key=lambda p: p.melhor_erro)\n",
        "\n",
        "\n",
        "def treinar_federado(modelo_global, clientes, criterio, num_rodadas, INERCIA, C1, C2, testloader):\n",
        "    \"\"\"Treina os clientes localmente e sincroniza com o servidor central, validando a acurácia.\"\"\"\n",
        "\n",
        "    melhor_peso_global = copy.deepcopy(modelo_global.state_dict())  # Inicializa com o modelo global\n",
        "    melhor_erro_global = float('inf')\n",
        "    for rodada in range(num_rodadas):\n",
        "        resultados_rodada = []\n",
        "\n",
        "\n",
        "        for cliente in clientes:\n",
        "            cliente.treinar_com_pso(INERCIA, C1, C2, melhor_peso_global, criterio, rodada)  # Treino com PSO\n",
        "            cliente.refinar_com_adam(criterio)  # Refinamento com Adam\n",
        "            erro_cliente = cliente.melhor_particula.melhor_erro  # Obtém o melhor erro do cliente\n",
        "            resultados_rodada.append((cliente.cliente_id, erro_cliente))\n",
        "\n",
        "        resultados_sorted = sorted(resultados_rodada, key=lambda x: x[1])\n",
        "        top_3_results = resultados_sorted[:3]\n",
        "\n",
        "        melhor_cliente = random.choice(top_3_results)\n",
        "        melhor_cliente_id = melhor_cliente[0]\n",
        "        melhor_erro_cliente = melhor_cliente[1]\n",
        "\n",
        "        melhor_peso_global = copy.deepcopy(clientes[melhor_cliente_id].melhor_particula.pesos)\n",
        "        melhor_peso_global_ajustado = {key.replace(\"_module.\", \"\"): value for key, value in melhor_peso_global.items()}\n",
        "        melhor_erro_global = melhor_erro_cliente\n",
        "\n",
        "        modelo_global.load_state_dict(melhor_peso_global_ajustado)\n",
        "\n",
        "        test_loss, test_accuracy = avaliar_modelo(modelo_global, criterio, testloader)\n",
        "\n",
        "\n",
        "        print(f\"Rodada {rodada+1}/{num_rodadas}: Cliente {melhor_cliente_id} enviou os pesos.\")\n",
        "        print(f\"Erro Global Atualizado: {melhor_erro_global:.4f}\")\n",
        "        print(f\"Teste -> Perda: {test_loss:.4f}, Acurácia: {test_accuracy:.2f}%\\n\")\n",
        "\n",
        "    print(\"Treinamento Federado Finalizado!\")\n",
        "\n",
        "def avaliar_modelo(modelo, criterio, testloader):\n",
        "    \"\"\"Avalia o modelo global no conjunto de teste.\"\"\"\n",
        "    modelo.eval()  # Modo de avaliação\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = modelo(inputs)\n",
        "            loss = criterio(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    test_loss = total_loss / len(testloader)\n",
        "    test_accuracy = (correct / total_samples) * 100\n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "X_train = mnist_train.data.view(-1, 28*28).numpy()  # Flatten (Transforma 28x28 em 784)\n",
        "y_train = mnist_train.targets.numpy()  # Labels\n",
        "\n",
        "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
        "X_test = mnist_test.data.view(-1, 28*28).numpy()  # Flatten (Transforma 28x28 em 784)\n",
        "y_test = mnist_test.targets.numpy()  # Labels\n",
        "\n",
        "# Dividir treino e teste manualmente como no Iris\n",
        "\n",
        "# Normalizar como no Iris\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Converter para tensores\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Criar datasets como no Iris\n",
        "trainset = TensorDataset(X_train, y_train)\n",
        "testset = TensorDataset(X_test, y_test)\n",
        "\n",
        "\n",
        "trainloaders = create_subset(trainset, NUM_CLIENTES)\n",
        "\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "noise = get_noise_multiplier(target_epsilon = 5,\n",
        "                             target_delta = 1e-5,\n",
        "                             sample_rate = BATCH_SIZE/12000,\n",
        "                             epochs = 10)\n",
        "\n",
        "\n",
        "# Criando os clientes\n",
        "clientes = [Cliente(i, modelo_global, trainloaders[i], NUM_PARTICULAS) for i in range(NUM_CLIENTES)]\n",
        "privacy_engine_client_0 = PrivacyEngine()\n",
        "privacy_engine_client_1 = PrivacyEngine()\n",
        "privacy_engine_client_2 = PrivacyEngine()\n",
        "privacy_engine_client_3 = PrivacyEngine()\n",
        "privacy_engine_client_4 = PrivacyEngine()\n",
        "\n",
        "\n",
        "\n",
        "clientes[0].modelo, clientes[0].otimizador, clientes[0].dados = privacy_engine_client_0.make_private(\n",
        "    module=clientes[0].modelo,\n",
        "    optimizer=clientes[0].otimizador,\n",
        "    data_loader=clientes[0].dados,  # Seu DataLoader\n",
        "    noise_multiplier=noise,      # Controle o nível de ruído\n",
        "    max_grad_norm=1.0,         # Clipping dos gradientes\n",
        ")\n",
        "clientes[1].modelo, clientes[1].otimizador, clientes[1].dados = privacy_engine_client_1.make_private(\n",
        "    module=clientes[1].modelo,\n",
        "    optimizer=clientes[1].otimizador,\n",
        "    data_loader=clientes[1].dados,  # Seu DataLoader\n",
        "    noise_multiplier=noise,      # Controle o nível de ruído\n",
        "    max_grad_norm=1.0,         # Clipping dos gradientes\n",
        ")\n",
        "clientes[2].modelo, clientes[2].otimizador, clientes[2].dados = privacy_engine_client_2.make_private(\n",
        "    module=clientes[2].modelo,\n",
        "    optimizer=clientes[2].otimizador,\n",
        "    data_loader=clientes[2].dados,  # Seu DataLoader\n",
        "    noise_multiplier=noise,      # Controle o nível de ruído\n",
        "    max_grad_norm=1.0,         # Clipping dos gradientes\n",
        ")\n",
        "clientes[3].modelo, clientes[3].otimizador, clientes[3].dados = privacy_engine_client_3.make_private(\n",
        "    module=clientes[3].modelo,\n",
        "    optimizer=clientes[3].otimizador,\n",
        "    data_loader=clientes[3].dados,  # Seu DataLoader\n",
        "    noise_multiplier=noise,      # Controle o nível de ruído\n",
        "    max_grad_norm=1.0,         # Clipping dos gradientes\n",
        ")\n",
        "clientes[4].modelo, clientes[4].otimizador, clientes[4].dados = privacy_engine_client_4.make_private(\n",
        "    module=clientes[4].modelo,\n",
        "    optimizer=clientes[4].otimizador,\n",
        "    data_loader=clientes[4].dados,  # Seu DataLoader\n",
        "    noise_multiplier=noise,      # Controle o nível de ruído\n",
        "    max_grad_norm=1.0,         # Clipping dos gradientes\n",
        ")\n",
        "\n",
        "# Executando o treinamento federado\n",
        "treinar_federado(modelo_global, clientes, criterio, NUM_RODADAS, INERCIA, C1, C2, testloader)\n",
        "print(f\"Orçamento de privacidade (epsilon) Cliente 0: {privacy_engine_client_0.get_epsilon(delta = 1e-5)}\")\n",
        "print(f\"Orçamento de privacidade (epsilon) Cliente 1: {privacy_engine_client_1.get_epsilon(delta = 1e-5)}\")\n",
        "print(f\"Orçamento de privacidade (epsilon) Cliente 2: {privacy_engine_client_2.get_epsilon(delta = 1e-5)}\")\n",
        "print(f\"Orçamento de privacidade (epsilon) Cliente 3: {privacy_engine_client_3.get_epsilon(delta = 1e-5)}\")\n",
        "print(f\"Orçamento de privacidade (epsilon) Cliente 4: {privacy_engine_client_4.get_epsilon(delta = 1e-5)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkL-eId7AF03",
        "outputId": "2c76fcb2-8ae8-49a1-f511-4d48a2a3b36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodada 1/10: Cliente 0 enviou os pesos.\n",
            "Erro Global Atualizado: 2.2985\n",
            "Teste -> Perda: 0.8366, Acurácia: 84.50%\n",
            "\n",
            "Rodada 2/10: Cliente 0 enviou os pesos.\n",
            "Erro Global Atualizado: 0.5436\n",
            "Teste -> Perda: 0.6486, Acurácia: 88.26%\n",
            "\n",
            "Rodada 3/10: Cliente 1 enviou os pesos.\n",
            "Erro Global Atualizado: 0.4427\n",
            "Teste -> Perda: 0.6451, Acurácia: 88.81%\n",
            "\n",
            "Rodada 4/10: Cliente 1 enviou os pesos.\n",
            "Erro Global Atualizado: 0.4427\n",
            "Teste -> Perda: 0.5999, Acurácia: 89.21%\n",
            "\n",
            "Rodada 5/10: Cliente 1 enviou os pesos.\n",
            "Erro Global Atualizado: 0.3906\n",
            "Teste -> Perda: 0.6592, Acurácia: 89.27%\n",
            "\n",
            "Rodada 6/10: Cliente 0 enviou os pesos.\n",
            "Erro Global Atualizado: 0.4332\n",
            "Teste -> Perda: 0.6088, Acurácia: 89.17%\n",
            "\n",
            "Rodada 7/10: Cliente 0 enviou os pesos.\n",
            "Erro Global Atualizado: 0.3734\n",
            "Teste -> Perda: 0.5920, Acurácia: 89.57%\n",
            "\n",
            "Rodada 8/10: Cliente 2 enviou os pesos.\n",
            "Erro Global Atualizado: 0.3951\n",
            "Teste -> Perda: 0.6076, Acurácia: 89.70%\n",
            "\n",
            "Rodada 9/10: Cliente 0 enviou os pesos.\n",
            "Erro Global Atualizado: 0.3734\n",
            "Teste -> Perda: 0.5579, Acurácia: 89.70%\n",
            "\n",
            "Rodada 10/10: Cliente 2 enviou os pesos.\n",
            "Erro Global Atualizado: 0.3883\n",
            "Teste -> Perda: 0.5737, Acurácia: 89.96%\n",
            "\n",
            "Treinamento Federado Finalizado!\n",
            "Orçamento de privacidade (epsilon) Cliente 0: 4.417680295219723\n",
            "Orçamento de privacidade (epsilon) Cliente 1: 4.417680295219723\n",
            "Orçamento de privacidade (epsilon) Cliente 2: 4.417680295219723\n",
            "Orçamento de privacidade (epsilon) Cliente 3: 4.417680295219723\n",
            "Orçamento de privacidade (epsilon) Cliente 4: 4.417680295219723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " '''sigma = SENSITIVITY * torch.sqrt((2.0 * torch.log(torch.tensor(1.0 / DELTA))).clone().detach()) / EPSILON\n",
        "              if i==4:\n",
        "                # Percorrer todos os parâmetros do modelo e adicionar ruído aos gradientes\n",
        "                for param in self.modelo.parameters():\n",
        "                    if param.grad is not None:\n",
        "                        torch.nn.utils.clip_grad_norm_(self.modelo.parameters(), MAX_NORM)\n",
        "                        noise = torch.normal(mean=0, std=sigma, size=param.grad.shape, device=param.grad.device)\n",
        "                        param.grad += noise  # 🔹 Adiciona ruído diretamente ao gradiente'''"
      ],
      "metadata": {
        "id": "w7tgCKOD85iX"
      }
    }
  ]
}