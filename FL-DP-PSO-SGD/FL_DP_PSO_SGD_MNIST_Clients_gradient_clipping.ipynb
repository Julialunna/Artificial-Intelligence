{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julialunna/Artificial-Intelligence/blob/main/FL-DP-PSO-SGD/FL_DP_PSO_SGD_MNIST_Clients_gradient_clipping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opacus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-88k_b5RxwsM",
        "outputId": "57d206dc-a7c5-4c6a-e593-ab9b81e596fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opacus in /usr/local/lib/python3.11/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, Subset, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import random\n",
        "import csv\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
        "from copy import deepcopy"
      ],
      "metadata": {
        "id": "AasvJNQd54yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, device, input_size=28*28, hidden_size=128, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.device = device\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Achatar o tensor de entrada\n",
        "        y = self.fc1(x)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc3(y)\n",
        "\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "DK3gmoasMO_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defini칞칫es dos hiperpar칙metros\n",
        "NUM_CLIENTES = 5\n",
        "NUM_PARTICULAS = 20\n",
        "NUM_RODADAS = 10\n",
        "INERCIA, C1, C2 = 0.9, 0.8, 0.9\n",
        "EPSILON = 6/math.sqrt(50)\n",
        "DELTA = 1e-5\n",
        "SENSITIVITY = 4\n",
        "MAX_NORM = 2.0\n",
        "SUBSET_SIZE = 12000\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'training on {DEVICE}')\n",
        "\n",
        "# Criando o modelo global\n",
        "modelo_global = MLP(DEVICE, hidden_size=256)\n",
        "criterio = nn.CrossEntropyLoss()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOsKzlgWLN5r",
        "outputId": "883cf069-54e6-4a19-a46e-f1c0d98c75e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seeds para reprodutibilidade\n",
        "random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "\n",
        "\n",
        "def create_subset(dataset, num_clients):\n",
        "    indices = list(range(len(dataset)))  # Lista de todos os 칤ndices\n",
        "    random.shuffle(indices)  # Embaralha os 칤ndices para aleatoriedade\n",
        "\n",
        "    subset_size = len(indices) // num_clients  # Tamanho de cada subconjunto\n",
        "    subsets = [Subset(dataset, indices[i * subset_size : (i + 1) * subset_size]) for i in range(num_clients)]\n",
        "\n",
        "    dataloaders = [\n",
        "        DataLoader(subset, batch_size=32, shuffle=False)\n",
        "        for subset in subsets\n",
        "    ]\n",
        "    return dataloaders\n",
        "\n",
        "    return dataloaders\n",
        "def add_module_prefix(state_dict):\n",
        "    new_state_dict = {}\n",
        "    for key, value in state_dict.items():\n",
        "        new_key = f\"_module.{key}\"  # Adiciona o prefixo `_module`\n",
        "        new_state_dict[new_key] = value\n",
        "    return new_state_dict\n",
        "\n",
        "class Particula:\n",
        "    def __init__(self, particle_id, modelo_cliente):\n",
        "        self.particle_id = particle_id\n",
        "        self.pesos = {f\"_module.{key}\": value.clone() for key, value in modelo_cliente.state_dict().items()}\n",
        "        self.melhor_pesos = copy.deepcopy(self.pesos)  # pbest (melhor posi칞칚o da part칤cula)\n",
        "        self.melhor_erro = float('inf')  # Melhor erro alcan칞ado\n",
        "        self.velocidade = {name: torch.zeros_like(param) for name, param in self.pesos.items()}  # Velocidade do PSO\n",
        "        self.device = modelo_cliente.device  # Dispositivo do modelo\n",
        "\n",
        "    def atualizar_pso(self, global_best_pesos, INERCIA, C1, C2, rodada):\n",
        "        \"\"\"Atualiza os pesos da part칤cula usando a equa칞칚o do PSO.\"\"\"\n",
        "        global_best_pesos_ajustados = global_best_pesos\n",
        "        if(rodada == 0):\n",
        "          global_best_pesos_ajustados = {f\"_module.{key}\": value for key, value in global_best_pesos.items()}\n",
        "        for name in self.pesos:\n",
        "            local_rand = random.random()\n",
        "            global_rand = random.random()\n",
        "            self.velocidade[name] = (\n",
        "                INERCIA * self.velocidade[name] +\n",
        "                C1 * local_rand * (self.melhor_pesos[name] - self.pesos[name]) +\n",
        "                C2 * global_rand * (global_best_pesos_ajustados[name] - self.pesos[name])\n",
        "            )\n",
        "            self.pesos[name] += self.velocidade[name]\n",
        "            ''' sigma = SENSITIVITY * torch.sqrt((2.0 * torch.log(torch.tensor(1.0 / DELTA))).clone().detach()) / EPSILON\n",
        "\n",
        "              # Gerar ru칤do diretamente com a distribui칞칚o normal do PyTorch (muito mais eficiente!)\n",
        "              noise = torch.normal(mean=0, std=sigma, size=self.velocidade[name].shape, device=self.device)\n",
        "              self.velocidade[name] += noise\n",
        "              #clipping velocity\n",
        "              self.velocidade[name] = torch.clamp(self.velocidade[name], -MAX_VELOCITY, MAX_VELOCITY)'''\n",
        "\n",
        "    def avaliar_perda(self, modelo_cliente, criterio, dados):\n",
        "        \"\"\"Calcula a perda da part칤cula no modelo do cliente.\"\"\"\n",
        "        #pesos_ajustados = {f\"_module.{key}\": value for key, value in self.pesos.items()}\n",
        "\n",
        "        modelo_cliente.load_state_dict(self.pesos)  # Aplica os pesos da part칤cula no modelo do cliente\n",
        "        modelo_cliente.eval()\n",
        "        total_loss = 0\n",
        "        device = next(modelo_cliente.parameters()).device\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dados:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = modelo_cliente(inputs)\n",
        "                loss = criterio(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        return total_loss / len(dados)\n",
        "\n",
        "\n",
        "class Cliente:\n",
        "    def __init__(self, cliente_id, modelo_global, dados, num_particulas=5):\n",
        "        self.cliente_id = cliente_id\n",
        "        self.modelo = copy.deepcopy(modelo_global)  # Cada cliente tem seu pr칩prio modelo\n",
        "        self.dados = dados\n",
        "        self.num_particulas = num_particulas\n",
        "        self.particulas = []\n",
        "        self.melhor_particula = None\n",
        "        self.inicializar_particulas(num_particulas)\n",
        "        self.otimizador = optim.Adam(self.modelo.parameters(), lr=0.009, weight_decay=1e-5)\n",
        "\n",
        "    def inicializar_particulas(self, num_particulas):\n",
        "        \"\"\"Cria um conjunto de part칤culas associadas ao cliente.\"\"\"\n",
        "        self.particulas = [Particula(i, self.modelo) for i in range(num_particulas)]\n",
        "\n",
        "    def treinar_com_pso(self, INERCIA, C1, C2, global_best_pesos, criterio, rodada):\n",
        "        \"\"\"Treina as part칤culas usando PSO e atualiza a melhor part칤cula local.\"\"\"\n",
        "\n",
        "        for particula in self.particulas:\n",
        "            particula.atualizar_pso(global_best_pesos, INERCIA, C1, C2, rodada)\n",
        "            erro = particula.avaliar_perda(self.modelo, criterio, self.dados)\n",
        "            if erro < particula.melhor_erro:\n",
        "                particula.melhor_erro = erro\n",
        "                particula.melhor_pesos = copy.deepcopy(particula.pesos)\n",
        "\n",
        "        self.selecionar_melhor_particula()\n",
        "\n",
        "    def refinar_com_adam(self, criterio, EPSILON, DELTA, MAX_NORM, SENSITIVITY):\n",
        "        \"\"\"Refina os pesos da melhor part칤cula usando Adam.\"\"\"\n",
        "        self.modelo.load_state_dict(self.melhor_particula.melhor_pesos)\n",
        "        #train_loader = DataLoader(self.dados, batch_size=32, shuffle=True)\n",
        "        device = next(self.modelo.parameters()).device\n",
        "        self.modelo.train()\n",
        "        for i in range(2):  # 10 칠pocas de refinamento com Adam\n",
        "          with BatchMemoryManager(data_loader=self.dados, max_physical_batch_size=32, optimizer=self.otimizador) as new_data_loader:\n",
        "            for inputs, labels in new_data_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                self.otimizador.zero_grad()\n",
        "                outputs = self.modelo(inputs)\n",
        "                loss = criterio(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.otimizador.step()\n",
        "        # Atualiza os pesos da melhor part칤cula com os pesos refinados pelo Adam\n",
        "        self.melhor_particula.pesos = copy.deepcopy(self.modelo.state_dict())\n",
        "\n",
        "    def selecionar_melhor_particula(self):\n",
        "        \"\"\"Seleciona a melhor part칤cula do cliente.\"\"\"\n",
        "        self.melhor_particula = min(self.particulas, key=lambda p: p.melhor_erro)\n",
        "\n",
        "\n",
        "def treinar_federado(modelo_global, clientes, criterio, num_rodadas, INERCIA, C1, C2, testloader, EPSILON, DELTA, MAX_NORM, SENSITIVITY):\n",
        "    \"\"\"Treina os clientes localmente e sincroniza com o servidor central, validando a acur치cia.\"\"\"\n",
        "\n",
        "    melhor_peso_global = copy.deepcopy(modelo_global.state_dict())  # Inicializa com o modelo global\n",
        "    melhor_erro_global = float('inf')\n",
        "    for rodada in range(num_rodadas):\n",
        "        resultados_rodada = []\n",
        "\n",
        "\n",
        "        for cliente in clientes:\n",
        "            cliente.treinar_com_pso(INERCIA, C1, C2, melhor_peso_global, criterio, rodada)  # Treino com PSO\n",
        "            cliente.refinar_com_adam(criterio, EPSILON, DELTA, MAX_NORM, SENSITIVITY)  # Refinamento com Adam\n",
        "            erro_cliente = cliente.melhor_particula.melhor_erro  # Obt칠m o melhor erro do cliente\n",
        "            resultados_rodada.append((cliente.cliente_id, erro_cliente))\n",
        "\n",
        "        resultados_sorted = sorted(resultados_rodada, key=lambda x: x[1])\n",
        "        top_3_results = resultados_sorted[:3]\n",
        "\n",
        "        melhor_cliente = random.choice(top_3_results)\n",
        "        melhor_cliente_id = melhor_cliente[0]\n",
        "        melhor_erro_cliente = melhor_cliente[1]\n",
        "\n",
        "        melhor_peso_global = copy.deepcopy(clientes[melhor_cliente_id].melhor_particula.pesos)\n",
        "        melhor_peso_global_ajustado = {key.replace(\"_module.\", \"\"): value for key, value in melhor_peso_global.items()}\n",
        "        melhor_erro_global = melhor_erro_cliente\n",
        "\n",
        "        modelo_global.load_state_dict(melhor_peso_global_ajustado)\n",
        "\n",
        "        test_loss, test_accuracy = avaliar_modelo(modelo_global, criterio, testloader)\n",
        "\n",
        "\n",
        "        print(f\"Rodada {rodada+1}/{num_rodadas}: Cliente {melhor_cliente_id} enviou os pesos.\")\n",
        "        print(f\"Erro Global Atualizado: {melhor_erro_global:.4f}\")\n",
        "        print(f\"Teste -> Perda: {test_loss:.4f}, Acur치cia: {test_accuracy:.2f}%\\n\")\n",
        "\n",
        "    print(\"Treinamento Federado Finalizado!\")\n",
        "\n",
        "def avaliar_modelo(modelo, criterio, testloader):\n",
        "    \"\"\"Avalia o modelo global no conjunto de teste.\"\"\"\n",
        "    modelo.eval()  # Modo de avalia칞칚o\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = modelo(inputs)\n",
        "            loss = criterio(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    test_loss = total_loss / len(testloader)\n",
        "    test_accuracy = (correct / total_samples) * 100\n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "X_train = mnist_train.data.view(-1, 28*28).numpy()  # Flatten (Transforma 28x28 em 784)\n",
        "y_train = mnist_train.targets.numpy()  # Labels\n",
        "\n",
        "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
        "X_test = mnist_test.data.view(-1, 28*28).numpy()  # Flatten (Transforma 28x28 em 784)\n",
        "y_test = mnist_test.targets.numpy()  # Labels\n",
        "\n",
        "# Dividir treino e teste manualmente como no Iris\n",
        "\n",
        "# Normalizar como no Iris\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Converter para tensores\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Criar datasets como no Iris\n",
        "trainset = TensorDataset(X_train, y_train)\n",
        "testset = TensorDataset(X_test, y_test)\n",
        "\n",
        "\n",
        "trainloaders = create_subset(trainset, NUM_CLIENTES)\n",
        "\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Criando os clientes\n",
        "clientes = [Cliente(i, modelo_global, trainloaders[i], NUM_PARTICULAS) for i in range(NUM_CLIENTES)]\n",
        "privacy_engine = PrivacyEngine()\n",
        "for cliente in clientes:\n",
        "\n",
        "    cliente.modelo, cliente.otimizador, cliente.dados = privacy_engine.make_private(\n",
        "        module=cliente.modelo,\n",
        "        optimizer=cliente.otimizador,\n",
        "        data_loader=cliente.dados,  # Seu DataLoader\n",
        "        noise_multiplier=1.0,      # Controle o n칤vel de ru칤do\n",
        "        max_grad_norm=1.0,         # Clipping dos gradientes\n",
        "    )\n",
        "\n",
        "# Executando o treinamento federado\n",
        "treinar_federado(modelo_global, clientes, criterio, NUM_RODADAS, INERCIA, C1, C2, testloader, EPSILON, DELTA, MAX_NORM, SENSITIVITY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkL-eId7AF03",
        "outputId": "c20afc05-8453-4e13-ead1-99f38027934d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:152: UserWarning: PrivacyEngine detected new dataset object. Was: <torch.utils.data.dataset.Subset object at 0x7cf9ec204250>, got: <torch.utils.data.dataset.Subset object at 0x7cf8d7478550>. Privacy accounting works per dataset, please initialize new PrivacyEngine if you're using different dataset. You can ignore this warning if two datasets above represent the same logical dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:152: UserWarning: PrivacyEngine detected new dataset object. Was: <torch.utils.data.dataset.Subset object at 0x7cf9ec204250>, got: <torch.utils.data.dataset.Subset object at 0x7cf8d54bdd10>. Privacy accounting works per dataset, please initialize new PrivacyEngine if you're using different dataset. You can ignore this warning if two datasets above represent the same logical dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:152: UserWarning: PrivacyEngine detected new dataset object. Was: <torch.utils.data.dataset.Subset object at 0x7cf9ec204250>, got: <torch.utils.data.dataset.Subset object at 0x7cf8d54bde10>. Privacy accounting works per dataset, please initialize new PrivacyEngine if you're using different dataset. You can ignore this warning if two datasets above represent the same logical dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:152: UserWarning: PrivacyEngine detected new dataset object. Was: <torch.utils.data.dataset.Subset object at 0x7cf9ec204250>, got: <torch.utils.data.dataset.Subset object at 0x7cf8d54d8ad0>. Privacy accounting works per dataset, please initialize new PrivacyEngine if you're using different dataset. You can ignore this warning if two datasets above represent the same logical dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Or칞amento de privacidade (epsilon): 0.3927540007540384\n",
            "Or칞amento de privacidade (epsilon): 0.5393654888296165\n",
            "Or칞amento de privacidade (epsilon): 0.6556080797823618\n",
            "Or칞amento de privacidade (epsilon): 0.755633773051966\n",
            "Or칞amento de privacidade (epsilon): 0.8450930708957664\n",
            "Rodada 1/10: Cliente 1 enviou os pesos.\n",
            "Erro Global Atualizado: 2.3031\n",
            "Teste -> Perda: 14.4568, Acur치cia: 57.09%\n",
            "\n",
            "Or칞amento de privacidade (epsilon): 0.9269443141464594\n",
            "Or칞amento de privacidade (epsilon): 1.0029718383215807\n",
            "Or칞amento de privacidade (epsilon): 1.0743517871364325\n",
            "Or칞amento de privacidade (epsilon): 1.1419087200218854\n",
            "Or칞amento de privacidade (epsilon): 1.2062475900442695\n",
            "Rodada 2/10: Cliente 3 enviou os pesos.\n",
            "Erro Global Atualizado: 1.7593\n",
            "Teste -> Perda: 15.1565, Acur치cia: 59.02%\n",
            "\n",
            "Or칞amento de privacidade (epsilon): 1.2678280003845996\n",
            "Or칞amento de privacidade (epsilon): 1.3270090378745394\n",
            "Or칞amento de privacidade (epsilon): 1.3840776029556454\n",
            "Or칞amento de privacidade (epsilon): 1.4392672981213503\n",
            "Or칞amento de privacidade (epsilon): 1.4927713431852816\n",
            "Rodada 3/10: Cliente 3 enviou os pesos.\n",
            "Erro Global Atualizado: 1.5830\n",
            "Teste -> Perda: 16.9487, Acur치cia: 61.73%\n",
            "\n",
            "Or칞amento de privacidade (epsilon): 1.5447518041038413\n",
            "Or칞amento de privacidade (epsilon): 1.5953461304052488\n",
            "Or칞amento de privacidade (epsilon): 1.6446722456667608\n",
            "Or칞amento de privacidade (epsilon): 1.692832054827479\n",
            "Or칞amento de privacidade (epsilon): 1.7399144441359728\n",
            "Rodada 4/10: Cliente 3 enviou os pesos.\n",
            "Erro Global Atualizado: 1.5830\n",
            "Teste -> Perda: 16.6251, Acur치cia: 58.48%\n",
            "\n",
            "Or칞amento de privacidade (epsilon): 1.7859975528017966\n",
            "Or칞amento de privacidade (epsilon): 1.8311503599994867\n",
            "Or칞amento de privacidade (epsilon): 1.8754343118084558\n",
            "Or칞amento de privacidade (epsilon): 1.9189042624321828\n",
            "Or칞amento de privacidade (epsilon): 1.9616094395859733\n",
            "Rodada 5/10: Cliente 3 enviou os pesos.\n",
            "Erro Global Atualizado: 1.5830\n",
            "Teste -> Perda: 14.8004, Acur치cia: 61.42%\n",
            "\n",
            "Or칞amento de privacidade (epsilon): 2.0035944484041166\n",
            "Or칞amento de privacidade (epsilon): 2.0448994562654836\n",
            "Or칞amento de privacidade (epsilon): 2.085561273989278\n",
            "Or칞amento de privacidade (epsilon): 2.1256132161082357\n",
            "Or칞amento de privacidade (epsilon): 2.165085977498873\n",
            "Rodada 6/10: Cliente 4 enviou os pesos.\n",
            "Erro Global Atualizado: 1.6826\n",
            "Teste -> Perda: 16.7510, Acur치cia: 61.73%\n",
            "\n",
            "Or칞amento de privacidade (epsilon): 2.204007768495337\n",
            "Or칞amento de privacidade (epsilon): 2.242404469971018\n",
            "Or칞amento de privacidade (epsilon): 2.2802999604120466\n",
            "Or칞amento de privacidade (epsilon): 2.3177164188869943\n",
            "Or칞amento de privacidade (epsilon): 2.354674379324146\n",
            "Rodada 7/10: Cliente 4 enviou os pesos.\n",
            "Erro Global Atualizado: 1.6826\n",
            "Teste -> Perda: 14.9822, Acur치cia: 61.02%\n",
            "\n",
            "Or칞amento de privacidade (epsilon): 2.3911930797410177\n",
            "Or칞amento de privacidade (epsilon): 2.427290254962275\n",
            "Or칞amento de privacidade (epsilon): 2.4629825377590384\n",
            "Or칞amento de privacidade (epsilon): 2.498285505492497\n",
            "Or칞amento de privacidade (epsilon): 2.5332137840828155\n",
            "Rodada 8/10: Cliente 4 enviou os pesos.\n",
            "Erro Global Atualizado: 1.6826\n",
            "Teste -> Perda: 15.4438, Acur치cia: 60.14%\n",
            "\n",
            "Or칞amento de privacidade (epsilon): 2.5677809988325566\n",
            "Or칞amento de privacidade (epsilon): 2.602000134221449\n",
            "Or칞amento de privacidade (epsilon): 2.635883182346426\n",
            "Or칞amento de privacidade (epsilon): 2.6694416769409575\n",
            "Or칞amento de privacidade (epsilon): 2.702686366207082\n",
            "Rodada 9/10: Cliente 3 enviou os pesos.\n",
            "Erro Global Atualizado: 1.5830\n",
            "Teste -> Perda: 15.6536, Acur치cia: 61.05%\n",
            "\n",
            "Or칞amento de privacidade (epsilon): 2.7356274081215624\n",
            "Or칞amento de privacidade (epsilon): 2.7682745568279366\n",
            "Or칞amento de privacidade (epsilon): 2.8006369429066695\n",
            "Or칞amento de privacidade (epsilon): 2.832723189166843\n",
            "Or칞amento de privacidade (epsilon): 2.86454145740599\n",
            "Rodada 10/10: Cliente 1 enviou os pesos.\n",
            "Erro Global Atualizado: 1.6779\n",
            "Teste -> Perda: 15.2910, Acur치cia: 60.18%\n",
            "\n",
            "Treinamento Federado Finalizado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " '''sigma = SENSITIVITY * torch.sqrt((2.0 * torch.log(torch.tensor(1.0 / DELTA))).clone().detach()) / EPSILON\n",
        "              if i==4:\n",
        "                # Percorrer todos os par칙metros do modelo e adicionar ru칤do aos gradientes\n",
        "                for param in self.modelo.parameters():\n",
        "                    if param.grad is not None:\n",
        "                        torch.nn.utils.clip_grad_norm_(self.modelo.parameters(), MAX_NORM)\n",
        "                        noise = torch.normal(mean=0, std=sigma, size=param.grad.shape, device=param.grad.device)\n",
        "                        param.grad += noise  # 游댳 Adiciona ru칤do diretamente ao gradiente'''"
      ],
      "metadata": {
        "id": "w7tgCKOD85iX"
      }
    }
  ]
}