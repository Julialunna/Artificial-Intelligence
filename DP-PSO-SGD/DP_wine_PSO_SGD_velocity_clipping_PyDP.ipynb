{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ+dE5alRpFPeqrbuoHlfM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julialunna/Artificial-Intelligence/blob/main/DP-PSO-SGD/DP_wine_PSO_SGD_velocity_clipping_PyDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwVthRPoYdnn",
        "outputId": "04aaef44-3b69-44ef-9b66-76d203bb8d05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dp\n",
            "  Downloading python_dp-1.1.4-cp311-cp311-manylinux1_x86_64.whl.metadata (5.1 kB)\n",
            "Downloading python_dp-1.1.4-cp311-cp311-manylinux1_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dp\n",
            "Successfully installed python-dp-1.1.4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install python-dp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "from pydp.algorithms.numerical_mechanisms import GaussianMechanism\n",
        "\n",
        "\n",
        "\n",
        "#preparing dataset\n",
        "wine = load_wine()\n",
        "# x is the carachteristics and y the labels\n",
        "x = wine.data\n",
        "y = wine.target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Padronizar os dados para média zero e variância unitária, melhora o treinamento\n",
        "#transforming trains and tests munpy arrays to tensors\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)  # Padroniza os dados de treino\n",
        "x_test = scaler.transform(x_test)  # Padroniza os dados de teste (usando os mesmos parâmetros do treino)\n",
        "\n",
        "# Converter para tensores do PyTorch\n",
        "x_train= torch.tensor(x_train, dtype=torch.float32)\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "#defining model\n",
        "#herda de torch.nn.Module\n",
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    #chama superclasse\n",
        "    super(MLP, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(input_size, 128)\n",
        "    self.fc2 = torch.nn.Linear(128, 64)\n",
        "    self.fc3 = torch.nn.Linear(64, 32)\n",
        "    self.fc4 = torch.nn.Linear(32, output_size)\n",
        "    #define o comportamento da rede neural\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = torch.relu(self.fc2(x))\n",
        "    x = torch.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Particle:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = copy.deepcopy(model).to(device)\n",
        "        self.best_model = copy.deepcopy(model).to(device)\n",
        "        # self.position = {name: torch.zeros_like(param).to(device) for name, param in model.named_parameters()}\n",
        "        # self.velocity = {name: torch.zeros_like(param).to(device) for name, param in model.named_parameters()}\n",
        "\n",
        "        # Definir os limites do espaço de busca e a escala da velocidade\n",
        "        #DIMINUIR LOW E HIGH\n",
        "        low = -10.0  # Limite inferior do espaço de busca\n",
        "        high = 10.0  # Limite superior do espaço de busca\n",
        "        velocity_scale = 0.1  # Escala para as velocidades iniciais\n",
        "\n",
        "        # Inicializar a posição com valores aleatórios uniformes no intervalo [low, high]\n",
        "        self.position = {name: torch.rand_like(param).to(device) * (high - low) + low for name, param in model.named_parameters()}\n",
        "\n",
        "        # Inicializar a velocidade com valores aleatórios pequenos (normalmente distribuídos)\n",
        "        self.velocity = {name: torch.randn_like(param).to(device) * velocity_scale for name, param in model.named_parameters()}\n",
        "\n",
        "        self.best_score = float('inf')\n",
        "        self.device = device\n",
        "\n",
        "        # Inicializar o otimizador (por exemplo, Adam)\n",
        "        #self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "\n",
        "    def pso(self, global_best_model, inertia, c1, c2):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            # if param.grad is None:\n",
        "            #     continue\n",
        "\n",
        "            local_rand = random.random()\n",
        "            global_rand = random.random()\n",
        "\n",
        "            # Atualização da velocidade\n",
        "            self.velocity[name] = (\n",
        "                inertia*self.velocity[name]\n",
        "                + c1*local_rand*(self.best_model.state_dict()[name].to(self.device) - param.data)\n",
        "                + c2*global_rand*(global_best_model.state_dict()[name].to(self.device) - param.data)\n",
        "            )\n",
        "\n",
        "            #calculating and adding noise\n",
        "            epsilon = 1.0\n",
        "            delta = 1e-5\n",
        "            sensitivity = 3\n",
        "            gaussian_mech = GaussianMechanism(epsilon, delta, sensitivity)\n",
        "            noise_tensor = torch.zeros_like(self.velocity[name])  # Cria um tensor de zeros com a mesma forma\n",
        "\n",
        "            if len(self.velocity[name].shape) == 2:  # Tensor 2D ([128, 13])\n",
        "              for i in range(self.velocity[name].shape[0]):  # Itera sobre as linhas\n",
        "                for j in range(self.velocity[name].shape[1]):  # Itera sobre as colunas\n",
        "                # Gera um ruído diferente para cada posição [i, j]\n",
        "                  noise = gaussian_mech.add_noise(0)\n",
        "                  self.velocity[name][i, j] += noise\n",
        "\n",
        "            elif len(self.velocity[name].shape) == 1:  # Tensor 1D ([128])\n",
        "              for i in range(self.velocity[name].shape[0]):  # Itera sobre os elementos\n",
        "            # Gera um ruído diferente para cada posição [i]\n",
        "                noise = gaussian_mech.add_noise(0)\n",
        "                self.velocity[name][i] += noise\n",
        "\n",
        "            # Gerar ruído diretamente para todos os elementos do tensor\n",
        "            #sigma = sensitivity * torch.sqrt(torch.tensor(2.0 * torch.log(torch.tensor(1.0 / delta)))) / epsilon\n",
        "\n",
        "            # Gerar ruído diretamente com a distribuição normal do PyTorch (muito mais eficiente!)\n",
        "            #noise = torch.normal(mean=0, std=sigma, size=self.velocity[name].shape, device=self.device)\n",
        "\n",
        "\n",
        "            self.velocity[name] += noise_tensor\n",
        "            #clipping velocity\n",
        "            self.velocity[name] = torch.clamp(self.velocity[name], -1.5, 1.5)\n",
        "\n",
        "            # Atualizar posição\n",
        "            self.position[name] = param.data + self.velocity[name]\n",
        "            param.data = self.position[name]\n",
        "\n",
        "    def evaluate_weights(self, x, y, criterion):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            acc = (predicted == y).sum().item() / len(x)\n",
        "        return loss.item(), acc*100\n",
        "\n",
        "\n",
        "\n",
        "# Definir os hiperparâmetros do PSO e do Adam\n",
        "pop_size = 10\n",
        "num_epochs = 150\n",
        "#inertia = 0.9\n",
        "c1, c2 = 0.8, 0.9\n",
        "learning_rate = 0.008\n",
        "beta1, beta2 = 0.9, 0.999\n",
        "epsilon = 1e-8\n",
        "\n",
        "\n",
        "model = MLP(input_size=x_train.size()[1], hidden_size=128, output_size=3)\n",
        "\n",
        "particles = [Particle(model, device) for _ in range(pop_size)]\n",
        "\n",
        "global_best_model = copy.deepcopy(particles[0].model)\n",
        "global_best_score = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Inicializar m e v para Adam\n",
        "overall_global_best_accuracy = 0.0\n",
        "overall_global_best_model = copy.deepcopy(global_best_model)\n",
        "\n",
        "# Loop de treinamento do PSO\n",
        "for epoch in range(num_epochs):\n",
        "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
        "    for particle in particles:\n",
        "        # Colocar o modelo em modo de treinamento\n",
        "        particle.model.train()\n",
        "\n",
        "        particle.optimizer.zero_grad()\n",
        "\n",
        "        # Treinar a partícula (atualização de posição)\n",
        "        particle.pso(global_best_model, inertia, c1, c2)\n",
        "\n",
        "        outputs = particle.model(x_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "        loss.backward()\n",
        "        particle.optimizer.step()\n",
        "\n",
        "        val_loss, val_acc = particle.evaluate_weights(x_train, y_train, criterion)\n",
        "\n",
        "        # Avaliar a partícula e atualizar o local best\n",
        "\n",
        "        if val_loss < particle.best_score:\n",
        "            particle.best_score = val_loss\n",
        "            particle.best_model = copy.deepcopy(particle.model)\n",
        "\n",
        "    #Determinar e atualizar o g-best (modelo global)\n",
        "    best_particle = min(particles, key=lambda p: p.best_score)\n",
        "    if best_particle.best_score < global_best_score:\n",
        "        global_best_score = best_particle.best_score\n",
        "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
        "    val_loss, val_accuracy = best_particle.evaluate_weights(x_test, y_test, criterion)\n",
        "    if val_accuracy > overall_global_best_accuracy:\n",
        "        overall_global_best_accuracy = val_accuracy\n",
        "        overall_global_best_model = copy.deepcopy(best_particle.best_model)\n",
        "\n",
        "    # Avaliar e imprimir a cada época\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.2f}, Validation Accuracy: {val_accuracy:.2f}')\n",
        "print(f'Best Models accuracy: {overall_global_best_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "LoHEvGMgYr8-",
        "outputId": "8b8798da-94e8-43aa-8da9-ebc054ad6ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/150, Validation Loss: 60155.04, Validation Accuracy: 33.33\n",
            "Epoch 20/150, Validation Loss: 129005.61, Validation Accuracy: 41.67\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-43e947e483d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# Treinar a partícula (atualização de posição)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mparticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-43e947e483d4>\u001b[0m in \u001b[0;36mpso\u001b[0;34m(self, global_best_model, inertia, c1, c2)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvelocity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Itera sobre as colunas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;31m# Gera um ruído diferente para cada posição [i, j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                   \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_mech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvelocity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}